{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/delay_emails.json') as f:\n",
    "    emails = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic model for supplier delays\n",
    "class ProductDelay(BaseModel):\n",
    "    supplier: str\n",
    "    qty: int\n",
    "    product: str\n",
    "    num_days_delay: int\n",
    "\n",
    "class AllSupplierDelays(BaseModel):\n",
    "    supplier_delay: Sequence[ProductDelay]\n",
    "\n",
    "# Set up a Pydantic parser and prompt template\n",
    "parser = PydanticOutputParser(pydantic_object=AllSupplierDelays)\n",
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "        Answer the user query.\n",
    "        \\n{format_instructions}\n",
    "        \\n{query}\n",
    "        \\n\",\n",
    "    ''',\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Function to process each email and extract information\n",
    "def process_email(email):\n",
    "    # Initialize LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4\")\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.invoke({\"query\": email})\n",
    "    \n",
    "    # Convert Pydantic result to a dictionary\n",
    "    supplier_delays_data = result.model_dump()\n",
    "\n",
    "    # Flatten the nested structure for DataFrame creation\n",
    "    data_dict = {'email': [], 'supplier': [], 'qty': [], 'product': [], 'num_days_delay': []}\n",
    "\n",
    "    for record in supplier_delays_data['supplier_delay']:\n",
    "        data_dict['email'].append(email)\n",
    "        data_dict['supplier'].append(record['supplier'])\n",
    "        data_dict['qty'].append(record['qty'])\n",
    "        data_dict['product'].append(record['product'])\n",
    "        data_dict['num_days_delay'].append(record['num_days_delay'])\n",
    "\n",
    "    # Create a DataFrame from the flattened data\n",
    "    delays_df = pd.DataFrame(data_dict)\n",
    "    return delays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "for item in emails:\n",
    "    email = item['email']\n",
    "    df_lst.append(process_email(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_delays = pd.concat(df_lst)\n",
    "product_delays.to_csv(\"data/product_delays.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_delays = pd.read_csv(\"data/product_delays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv(\"data/products_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_delays.rename(columns={'product': 'product_name'},\n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement logic to deal with plural and singular forms of the same product noun\n",
    "\n",
    "# Hack: manually map product name for now\n",
    "MANUAL_PRODUCT_MAP = {\n",
    "    'Passionfruits': 'Passionfruit'\n",
    "}\n",
    "\n",
    "product_delays['product_name'] = product_delays['product_name'].map(MANUAL_PRODUCT_MAP).fillna(product_delays['product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = product_delays.merge(products_df, on=['supplier', 'product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume for this grocery shop, we can place an urgent order with lead time of 1 day, for price = expedited price\n",
    "\n",
    "# First check if days of inventory can cover lead time + delay time. If not, we need to order the delta days 1 day before delta days\n",
    "\n",
    "merged_df['additional_order_days'] = merged_df['num_days_delay'] + merged_df['lead_time'] - merged_df['days_of_inventory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['reorder_date'] = (pd.to_datetime('today') + pd.to_timedelta(merged_df['days_of_inventory'], unit='d') - pd.Timedelta(days=1)).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_price_reorder(row):\n",
    "    '''\n",
    "    Check if it is worthwhile to reorder or just go OOS\n",
    "    logic: if expedited price is higher than product'shop price, \n",
    "    we will make a loss if we reorder, hence do not reorder\n",
    "    '''\n",
    "    if (row['expedited_price'] > row['price']) or (row['additional_order_days'] == 0):\n",
    "        return np.nan\n",
    "    return row['reorder_date']\n",
    "\n",
    "def calculate_reorder_qty(row):\n",
    "    '''\n",
    "    Check if it is worthwhile to reorder or just go OOS\n",
    "    logic: if expedited price is higher than product'shop price, \n",
    "    we will make a loss if we reorder, hence do not reorder\n",
    "    '''\n",
    "    if (row['expedited_price'] > row['price']) or (row['additional_order_days'] == 0):\n",
    "        return np.nan\n",
    "    return row['additional_order_days'] * row['daily_demand']\n",
    "\n",
    "merged_df['reorder_date'] = merged_df.apply(check_price_reorder, axis=1)\n",
    "merged_df['reorder_qty'] = merged_df.apply(calculate_reorder_qty, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['value_of_items_delayed'] = (merged_df['price'] - merged_df['cogs']) * merged_df['daily_demand'] * merged_df['num_days_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/c0k0z_096_n1727t5kbgcvxm0000gn/T/ipykernel_75081/3540302921.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reorder_summary_df.sort_values(by='value_of_items_delayed', ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "reorder_summary_df = merged_df[['product_id', 'product_name', 'price', 'expedited_price', 'daily_demand',\n",
    "                                'lead_time', 'num_days_delay', 'days_of_inventory',\t'additional_order_days',\n",
    "                                'reorder_date', 'reorder_qty', 'value_of_items_delayed']]\n",
    "\n",
    "reorder_summary_df.sort_values(by='value_of_items_delayed', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_summary_df.to_csv(\"data/reorder_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"data/product_delays_detailed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sco_llm",
   "language": "python",
   "name": "sco_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
